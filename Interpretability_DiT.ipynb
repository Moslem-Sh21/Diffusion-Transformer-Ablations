{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "L4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install diffusers torch requests pillow tqdm\n",
    "!pip install pycocotools\n",
    "!pip install torch-fidelity\n",
    "!pip install openai-clip\n",
    "!wget http://images.cocodataset.org/zips/val2017.zip\n",
    "!unzip -q val2017.zip\n",
    "!mkdir -p annotations\n",
    "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "!unzip -q annotations_trainval2017.zip -d annotations"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "antsyI6NVknX",
    "outputId": "bc0ef011-8893-4a36-b2b9-1c6334620079"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.33.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.32.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (6.0.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (1.1.2)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers) (3.22.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (2.0.9)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pycocotools) (2.0.2)\n",
      "Collecting torch-fidelity\n",
      "  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (2.0.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (11.2.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (1.15.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (0.21.0+cu124)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (4.67.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (4.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torch-fidelity) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torch-fidelity) (3.0.2)\n",
      "Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: torch-fidelity\n",
      "Successfully installed torch-fidelity-0.3.0\n",
      "Collecting openai-clip\n",
      "  Downloading openai-clip-1.0.1.tar.gz (1.4 MB)\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting ftfy (from openai-clip)\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from openai-clip) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-clip) (4.67.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->openai-clip) (0.2.13)\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-clip\n",
      "  Building wheel for openai-clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for openai-clip: filename=openai_clip-1.0.1-py3-none-any.whl size=1368605 sha256=a2d04bc388845f0cae35d839c709069dd734386819874e112b3021bdc542fcf9\n",
      "  Stored in directory: /root/.cache/pip/wheels/0d/17/90/042948fd2e2a87f1dcf6db6d438cad015c49db0c53d1d9c7dc\n",
      "Successfully built openai-clip\n",
      "Installing collected packages: ftfy, openai-clip\n",
      "Successfully installed ftfy-6.3.1 openai-clip-1.0.1\n",
      "--2025-06-13 15:21:00--  http://images.cocodataset.org/zips/val2017.zip\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.176.99, 3.5.27.73, 3.5.29.229, ...\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.176.99|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 815585330 (778M) [application/zip]\n",
      "Saving to: \u2018val2017.zip\u2019\n",
      "\n",
      "val2017.zip         100%[===================>] 777.80M  6.39MB/s    in 1m 44s  \n",
      "\n",
      "2025-06-13 15:22:44 (7.51 MB/s) - \u2018val2017.zip\u2019 saved [815585330/815585330]\n",
      "\n",
      "--2025-06-13 15:22:51--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.42.97, 3.5.29.87, 52.216.200.59, ...\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.42.97|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 252907541 (241M) [application/zip]\n",
      "Saving to: \u2018annotations_trainval2017.zip\u2019\n",
      "\n",
      "annotations_trainva 100%[===================>] 241.19M  17.2MB/s    in 16s     \n",
      "\n",
      "2025-06-13 15:23:07 (15.5 MB/s) - \u2018annotations_trainval2017.zip\u2019 saved [252907541/252907541]\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch_fidelity import calculate_metrics\n",
    "from diffusers import PixArtAlphaPipeline\n",
    "import clip\n",
    "import json\n",
    "\n",
    "# COCO paths\n",
    "COCO_ANN_PATH = \"annotations/annotations/captions_val2017.json\"\n",
    "COCO_IMG_DIR = \"./val2017\"\n",
    "N = 5  # Number of random samples\n",
    "\n",
    "def ablate_dit_part(dit, blocks_to_patch, part='ff', mode='zero'):\n",
    "    \"\"\"\n",
    "    Patch a given part ('attn1', 'attn2', 'ff') of DiT blocks in PixArt-\u03b1.\n",
    "\n",
    "    Args:\n",
    "        dit: The transformer model\n",
    "        blocks_to_patch: List of block indices to patch\n",
    "        part: 'attn1' (self-attn), 'attn2' (cross-attn), 'ff' (MLP)\n",
    "        mode: 'zero' | 'input' | 'mean'\n",
    "    \"\"\"\n",
    "    for idx in blocks_to_patch:\n",
    "        if idx >= len(dit.transformer_blocks):\n",
    "            print(f\"Warning: Block index {idx} exceeds available blocks ({len(dit.transformer_blocks)})\")\n",
    "            continue\n",
    "\n",
    "        block = dit.transformer_blocks[idx]\n",
    "        sub_module = getattr(block, part, None)\n",
    "\n",
    "        if sub_module is None:\n",
    "            print(f\"Warning: Part '{part}' not found in block {idx}\")\n",
    "            continue\n",
    "\n",
    "        # Store original forward method\n",
    "        if not hasattr(sub_module, '_original_forward'):\n",
    "            sub_module._original_forward = sub_module.forward\n",
    "\n",
    "        def create_ablated_forward(module, ablation_mode):\n",
    "            def ablated_forward(x, *args, **kwargs):\n",
    "                if ablation_mode == 'zero':\n",
    "                    return torch.zeros_like(x)\n",
    "                elif ablation_mode == 'input':\n",
    "                    return x\n",
    "                elif ablation_mode == 'mean':\n",
    "                    return x.mean(dim=-1, keepdim=True).expand_as(x)\n",
    "                else:\n",
    "                    return module._original_forward(x, *args, **kwargs)\n",
    "            return ablated_forward\n",
    "\n",
    "        # Apply the ablation\n",
    "        sub_module.forward = create_ablated_forward(sub_module, mode)\n",
    "        print(f\"Ablated block {idx}, part '{part}' with mode '{mode}'\")\n",
    "\n",
    "def restore_dit_part(dit, blocks_to_restore, part='ff'):\n",
    "    \"\"\"\n",
    "    Restore the original forward method for specified blocks and parts.\n",
    "    \"\"\"\n",
    "    for idx in blocks_to_restore:\n",
    "        if idx >= len(dit.transformer_blocks):\n",
    "            continue\n",
    "\n",
    "        block = dit.transformer_blocks[idx]\n",
    "        sub_module = getattr(block, part, None)\n",
    "\n",
    "        if sub_module is not None and hasattr(sub_module, '_original_forward'):\n",
    "            sub_module.forward = sub_module._original_forward\n",
    "            delattr(sub_module, '_original_forward')\n",
    "            print(f\"Restored block {idx}, part '{part}'\")\n",
    "\n",
    "# Load COCO data\n",
    "with open(COCO_ANN_PATH, \"r\") as f:\n",
    "    coco = json.load(f)\n",
    "\n",
    "id2filename = {img['id']: img['file_name'] for img in coco['images']}\n",
    "data = []\n",
    "for ann in coco['annotations']:\n",
    "    img_id = ann['image_id']\n",
    "    caption = ann['caption']\n",
    "    img_path = os.path.join(COCO_IMG_DIR, id2filename[img_id])\n",
    "    if os.path.exists(img_path):\n",
    "        data.append((img_path, caption))\n",
    "\n",
    "print(f\"Loaded {len(data)} (image, caption) pairs from COCO val2017.\")\n",
    "\n",
    "# Pick random samples with fixed seed\n",
    "random.seed(42)  # Set seed for reproducibility\n",
    "chosen = random.sample(data, N)\n",
    "\n",
    "# Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pipe = PixArtAlphaPipeline.from_pretrained(\n",
    "    \"PixArt-alpha/PixArt-XL-2-512x512\",\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True,\n",
    ")\n",
    "pipe.to(device)\n",
    "\n",
    "# Load CLIP\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "output_size = (299, 299)\n",
    "os.makedirs(\"./pixart_samples/real\", exist_ok=True)\n",
    "os.makedirs(\"./pixart_samples/fake\", exist_ok=True)\n",
    "os.makedirs(\"./pixart_samples/ablated\", exist_ok=True)\n",
    "\n",
    "# Generate original images\n",
    "print(\"Generating original images...\")\n",
    "for i, (img_path, prompt) in enumerate(tqdm(chosen, desc=\"Generating original\")):\n",
    "    gt_img = Image.open(img_path).convert(\"RGB\").resize(output_size, Image.LANCZOS)\n",
    "    gt_img.save(f\"./pixart_samples/real/gt_{i+1}.jpg\")\n",
    "\n",
    "    gen_img = pipe(prompt).images[0].convert(\"RGB\").resize(output_size, Image.LANCZOS)\n",
    "    gen_img.save(f\"./pixart_samples/fake/gen_{i+1}.jpg\")\n",
    "\n",
    "# Apply ablation\n",
    "print(f\"Total transformer blocks: {len(pipe.transformer.transformer_blocks)}\")\n",
    "\n",
    "# Example ablations - modify as needed:\n",
    "# ablate_dit_part(pipe.transformer, blocks_to_patch=[0], part='ff', mode='zero')\n",
    "# ablate_dit_part(pipe.transformer, blocks_to_patch=[1, 2], part='attn1', mode='input')\n",
    "ablate_dit_part(pipe.transformer, blocks_to_patch=[0], part='ff', mode='mean')\n",
    "\n",
    "# Generate ablated images\n",
    "print(\"Generating ablated images...\")\n",
    "for i, (img_path, prompt) in enumerate(tqdm(chosen, desc=\"Generating ablated\")):\n",
    "    ablated_img = pipe(prompt).images[0].convert(\"RGB\").resize(output_size, Image.LANCZOS)\n",
    "    ablated_img.save(f\"./pixart_samples/ablated/ablated_{i+1}.jpg\")\n",
    "\n",
    "# Calculate FID\n",
    "print(\"Calculating FID scores...\")\n",
    "print(\"FID (Original vs Real):\")\n",
    "fid_orig = calculate_metrics(\n",
    "    input1=\"./pixart_samples/real\",\n",
    "    input2=\"./pixart_samples/fake\",\n",
    "    cuda=torch.cuda.is_available(),\n",
    "    isc=False, kid=False, fid=True, verbose=True,\n",
    ")\n",
    "\n",
    "print(\"FID (Ablated vs Real):\")\n",
    "fid_ablate = calculate_metrics(\n",
    "    input1=\"./pixart_samples/real\",\n",
    "    input2=\"./pixart_samples/ablated\",\n",
    "    cuda=torch.cuda.is_available(),\n",
    "    isc=False, kid=False, fid=True, verbose=True,\n",
    ")\n",
    "\n",
    "print(f\"Original FID: {fid_orig['frechet_inception_distance']:.4f}\")\n",
    "print(f\"Ablated FID: {fid_ablate['frechet_inception_distance']:.4f}\")\n",
    "\n",
    "# Calculate CLIP scores\n",
    "def compute_clip_scores(img_dir, captions, prefix=\"gen\"):\n",
    "    scores = []\n",
    "    for i, (_, prompt) in enumerate(captions):\n",
    "        img = Image.open(f\"{img_dir}/{prefix}_{i+1}.jpg\").convert(\"RGB\")\n",
    "        img_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "        text = clip.tokenize([prompt]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            image_features = clip_model.encode_image(img_tensor)\n",
    "            text_features = clip_model.encode_text(text)\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "            text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "            similarity = (image_features @ text_features.T).item()\n",
    "        scores.append(similarity)\n",
    "    return scores\n",
    "\n",
    "print(\"Calculating CLIP scores...\")\n",
    "orig_clip_scores = compute_clip_scores(\"./pixart_samples/fake\", chosen, \"gen\")\n",
    "ablated_clip_scores = compute_clip_scores(\"./pixart_samples/ablated\", chosen, \"ablated\")\n",
    "\n",
    "print(f\"Mean CLIP (Original): {sum(orig_clip_scores)/len(orig_clip_scores):.4f}\")\n",
    "print(f\"Mean CLIP (Ablated): {sum(ablated_clip_scores)/len(ablated_clip_scores):.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "KaHbo7fDRiiE",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1db2cc0cfca6457c8170e9a44f94c6c2",
      "ee0518fe1d204b9893b1df78c9134bfd",
      "424137ced57749c7be0d1f58e28f802b",
      "d667bd7bc2c444df935b482b3fab8287",
      "8959b7e208fc4972953d90eadd64e7ea",
      "f03c6ac71ec743fdaa7a7fc920ec1765",
      "46b2b55b000544649c015b7587681ece",
      "fd751eb221994f9ba348afba37cbffeb",
      "bb17f5f7452a4a47aa02a4916d9ba846",
      "35f2ec4673e8452982845ce7f4356ec7",
      "bc3bc01516dc4d46be06cd3ca122b1b9",
      "cebc13c6e73b4c37bae442ffb0706339",
      "f960dfe28831486a9f6b2988f4a7dcd6",
      "638f6b2bbfd8469e8c90cdf5dffd6375",
      "de5695ca03c14327bbd420390ef94ec9",
      "18372d2184124605b0a765d133747361",
      "c8f44033e5a64377af1871843b3e3294",
      "399816b1e5444fe49b2a6bd4d0ae781e",
      "62fe5d717f534f2394f3d6e894c33c86",
      "339175e6bf094136900ff84859738834",
      "eaf66f75d2644d10a17fed69bb13c5fb",
      "66091c04a2a54549b749cb3ca6ed6ffe",
      "9a998439e78b4193b65bc86d55e651cb",
      "58df1fcafb424dc5acf405dcbbee467e",
      "ef56db332d8b420ca9a474c46502c3dd",
      "e8065f7ec6bf434d9492507113332d90",
      "8ffe6db5a30c40b4b173f489e8664fb1",
      "3cfe1ff74ed148edbe3d14ac4a1b9628",
      "61fe5c40dece4f03a8a2c8cde114e5d7",
      "443b1a547461455a9cda60e965489a51",
      "9f46370ef13d446fbe17e487ecfeaa7f",
      "e0047292cd294e88a945504beb345cde",
      "c3f14fe4db3a4dbca92b148bb4257820",
      "784d62fd88514925a4e168720fd879e9",
      "4dd535e0c0f34218bc3ede3f6705456c",
      "dd346cd56faf47d39d4ba16067074e12",
      "75a064b0c1aa42d4a9b0ff6276904546",
      "e49c8b9c54784efcba2d7b6760313542",
      "321c56e173fb48089a220b23c744534f",
      "170f24e395614b50bc170344b9040e0d",
      "93680104190e49debeedc1f9b42d8013",
      "e3f6632807594e79a7368e2fdec35fac",
      "d4b9115fba77499bbe4b91d53ef9214d",
      "e0baebea13f34d36b2ec5972dd94c8a6",
      "a1ba0462c0224ee2831a2f1ecb47829e",
      "7d1c546e196b4ae896c75a9f7ea096bb",
      "fba62f88a79f4c97a6e40af21979cfcc",
      "8f5b0c46cb654c2699e96c70911447f2",
      "9a4150dca58f41c48d075b0cf3814215",
      "b714525315ae445097fd94567676ccc1",
      "9939ce6ce09247b585ec679f6aaee635",
      "4557c84f3bf04348836337fc6f98082f",
      "24ce814d44a7482bb06764a60f43b6bc",
      "e00f5968a31c4ba6a3d7988a6d762e84",
      "26c9e76d6a1245e19b34bbd934f95218",
      "a6beaa3cb7954d5d8c61924eafc79861",
      "74bdd17b201647f4882771c7fe1d0de1",
      "2c66d0d86a9a493297b7053bc2db9041",
      "28d2669b911744d1bc5d2dd333f98e61",
      "f03d9779597f4814aa7904ff80aa9d29",
      "71cba2b729774d6d9c230228f4146df0",
      "82412257f6ea4f73a50e006f1ff8e89f",
      "21e120d829284fd683176accf8fceee4",
      "86c0a2cfa22048508f8ffb9bde809762",
      "a68d6376db0d4506872659b4e378bad4",
      "1d2ebf10363a4fc4ba559ea59f48427b",
      "1ca7ca8e92194f8aa3b2f66b1f795850",
      "103a06a57c7c494b8a702433a0716980",
      "5504b425d53e4253828580363180262b",
      "910aa68d1add4b2e8708e072e1c6e99b",
      "f9c28eebc01e432ab27d2390086cbe1d",
      "bcdd43186c2f4182845e3dab4e8e0a0f",
      "a4caa9af79af4fb1a25bfb7553dc2a3f",
      "b69ad1a2aa054afda289a74bd532c64a",
      "3b1f665c5bd14ed3be0813bbb0f5d085",
      "5b95b76cc53f41e0ac6e7137aa0f10ca",
      "fa38502206dd4ea7884d5a16133d0cf3",
      "08b7501446404ee9b45f7d9289506858",
      "7fcdb7cbf796428f97afbb894bf4daf5",
      "dfe41cf5292c44b4b49b526b1f7ae7ba",
      "b54874287fb64a048160a6f86e188b03",
      "a1265697d2e14eaab7fd4f5bd4eb2921",
      "aa7270ff52264fef895196542cc89a95",
      "62af2f047ad94d919f21137194812bb4",
      "4d4054e3a51d4011b04105c69ec6db0d",
      "a3ff5d125b71471d9d4ef08e3ab197b5",
      "105c6265192b46249a497a24b192f48b",
      "c862c1d8e8744f868d9cb795c6cc9c89",
      "ee80acc8cb614e4cad57b0e0923c496f",
      "0668c0b11ce9435195609a7531f4253b",
      "f153ba845e1b4406afe88f6822038db6",
      "85ab15d64d7244bca6bcc768e4c5d262",
      "dfc2854933c043f8b64b100f1c4762ad",
      "f9779ff0cb0b46e396cb7622e9d9b16c",
      "bac65fc2296345a0beaeb00ecb29ba45",
      "580f62e01d964aa1a00259b4b9f918b1",
      "f7c09bf4ed2e4685984e584b59c9ff87",
      "29385190e1c94d8a992c852781bbf21b",
      "9db985a290de4bcfa32517456706954c",
      "63153087417148bf8b44e801c1f4d2fb",
      "c9a3d6452fe94bcdbe2a4dfd4c1c3708",
      "febbd04423bf4a5fbfc284c4ca9d5840",
      "e8641b1b7b3f40e88c1c79e43ce0b909",
      "e790c8ff7b754ce88fda8c5e50573547",
      "044dd449bddf45bd86bf4a1478ce1229",
      "c7cde1e41c4e40e2af6230698a1887e0",
      "81a96787b34144459b828cdd63a6cea9",
      "a7d9f535bc1f46b48c7b5d34772933e0",
      "69bc1e6f1a6348e8bc8b4829a6b7029c",
      "ae9b3e89f0fc47efa75b40082a386722",
      "4fedaea316ef4aad92d249bfed51b6f6",
      "fc1b89f23a484911b93c812c3380584f",
      "7bf5f50b8b6f40459c8c153c55a205ca",
      "b2b2a085356540da8f03fd2c977561b0",
      "ec8ea810b036447a92ae49c03e925fec",
      "3b352b83cacd4e21bf78dff8cdc9a268",
      "f580bfbd48c04b9bbf08f8f7758b944f",
      "36794539c12d40e69045be4f833ea4a6",
      "dada31b72cfa45e5b0d2dd884db95e1c",
      "444757336743405eac6eb90ca64fcdfa",
      "9c80f01d785849d68a96b5434e821374",
      "791d14688448488da4324f21475e0a3b",
      "02579403a5944df3bc59c82fba30b171",
      "51422e24727845d3acb077c5d0f026ec",
      "50987e5a12fe4f6f9af71baa11482057",
      "fe42e1b707684e868b702798ebf47bb8",
      "0cf1cc7f38cc47bab3360f97ee259079",
      "02e01e2931214e6c804be0961709efe1",
      "6bf8e9d1bc3846aa99644ce6a525af6a",
      "9da1d02d19ab40c08740c2f3cbe76e06",
      "62acbe331f49455f874d621fcb76126a",
      "8f0557081d8a44158c9a26f370b373c2"
     ]
    },
    "outputId": "3b788a8a-7e5a-4ae8-aade-72c328e0d98d"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded 25014 (image, caption) pairs from COCO val2017.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1db2cc0cfca6457c8170e9a44f94c6c2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at /root/.cache/huggingface/hub/models--PixArt-alpha--PixArt-XL-2-512x512/snapshots/50f702106901db6d0f8b67eb88e814c56ded2692/transformer were not used when initializing PixArtTransformer2DModel: \n",
      " ['caption_projection.y_embedding']\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cebc13c6e73b4c37bae442ffb0706339"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generating original images...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rGenerating original:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a998439e78b4193b65bc86d55e651cb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rGenerating original:  20%|\u2588\u2588        | 1/5 [00:01<00:06,  1.69s/it]"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "784d62fd88514925a4e168720fd879e9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rGenerating original:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:03<00:05,  1.70s/it]"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1ba0462c0224ee2831a2f1ecb47829e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rGenerating original:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:05<00:03,  1.70s/it]"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6beaa3cb7954d5d8c61924eafc79861"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rGenerating original:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:06<00:01,  1.70s/it]"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ca7ca8e92194f8aa3b2f66b1f795850"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Generating original: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:08<00:00,  1.71s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total transformer blocks: 28\n",
      "Ablated block 0, part 'ff' with mode 'input'\n",
      "Generating ablated images...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rGenerating ablated:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08b7501446404ee9b45f7d9289506858"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rGenerating ablated:  20%|\u2588\u2588        | 1/5 [00:01<00:06,  1.70s/it]"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee80acc8cb614e4cad57b0e0923c496f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rGenerating ablated:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:03<00:05,  1.70s/it]"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "63153087417148bf8b44e801c1f4d2fb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rGenerating ablated:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:05<00:03,  1.71s/it]"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4fedaea316ef4aad92d249bfed51b6f6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rGenerating ablated:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:06<00:01,  1.71s/it]"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "791d14688448488da4324f21475e0a3b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Generating ablated: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:08<00:00,  1.71s/it]\n",
      "Creating feature extractor \"inception-v3-compat\" with features ['2048']\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Calculating FID scores...\n",
      "FID (Original vs Real):\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Extracting statistics from input 1\n",
      "Looking for samples non-recursivelty in \"./pixart_samples/real\" with extensions png,jpg,jpeg\n",
      "Found 5 samples, some are lossy-compressed - this may affect metrics\n",
      "Processing samples\n",
      "Extracting statistics from input 2\n",
      "Looking for samples non-recursivelty in \"./pixart_samples/fake\" with extensions png,jpg,jpeg\n",
      "Found 5 samples, some are lossy-compressed - this may affect metrics\n",
      "Processing samples\n",
      "Frechet Inception Distance: 532.1492532193625\n",
      "Creating feature extractor \"inception-v3-compat\" with features ['2048']\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FID (Ablated vs Real):\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Extracting statistics from input 1\n",
      "Looking for samples non-recursivelty in \"./pixart_samples/real\" with extensions png,jpg,jpeg\n",
      "Found 5 samples, some are lossy-compressed - this may affect metrics\n",
      "Processing samples\n",
      "Extracting statistics from input 2\n",
      "Looking for samples non-recursivelty in \"./pixart_samples/ablated\" with extensions png,jpg,jpeg\n",
      "Found 5 samples, some are lossy-compressed - this may affect metrics\n",
      "Processing samples\n",
      "Frechet Inception Distance: 696.7979340807983\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original FID: 532.1493\n",
      "Ablated FID: 696.7979\n",
      "Calculating CLIP scores...\n",
      "Mean CLIP (Original): 0.2885\n",
      "Mean CLIP (Ablated): 0.2084\n"
     ]
    }
   ]
  }
 ]
}